---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Education
======
* M.S. in Data Science, EPFL, 2021-2024
  * Thesis: "VLM Dataset Pruning"
  * Advisor: Prof. Martin Jaggi
  * Major GPA: 5.5/6.0
* B.S. in University of Electronic Science and Technology of China, 2017-2021

Research experience
======

* Oct.2023 - Feb.2024. Research Assistant, NLP Lab – EPFL.
  * Main goal: interpret the multi-modal models including ViLT, CLIP, and BLIP.
  * Tried different methods to understand how the image interacts with the text, such as the Second-Gradient Cross-Attention map,...

* Oct. 2023 – Feb. 2024. Research Assistant, Health NLP Lab – University of Tübingen.
  * Created a dataset benchmark, which contains corrupted sentences, correct sentences, contexts, and explanations, to measure LLM’s reliability.
  * Fine-tuned several widely used models to test their performance on explanation generation, including BERT, Flan-T5, BART, BRIO, GPT-2, and GPT-J.

* Jul. 2022 – Dec. 2022. Research Assistant, Machine Learning and Optimization Lab – EPFL.
  * Proposed a two-stage model SimSum for document-to-document simplification tasks, combining text simplification and summarization tasks innovatively.
  * Analysed and pre-processed two document-level simplification datasets, and made the resulting datasets available for reproducibility.
  * Paper was accepted to ACL 2023 main conference.


Work experience
======

* Feb.2023 - Aug.2023. NLP Research Intern, AXA Group Operation Switzerland.
  * Main Task: Automatic insurance claims generation for Coverage Check problem.
  * Explored prompts for ChatGPT to generate different insurance claims for model’s performance testing.
  * Deployed two Fake-Text-Detection models (MPU and DetectGPT) on Synthetic Text Detection subtasks.

  
  
